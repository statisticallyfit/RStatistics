runif(100, min=1, max=3)
?"sample"
sample(c(1,2,3), size=100, replace=TRUE)
sample(c(1,2,3), size=100, replace=F)
sample(c(1,2,3), size=100, replace=TRUE)
s <- sample(c(1,2,3), size=100, replace=TRUE)
s == 1
sum(s == 1)
sum(s == 2)
sum(s == 3)
s <- sample(c(1,2,3), size=100, replace=TRUE)
sum(s == 1)
sum(s == 2)
sum(s == 3)
s <- sample(c(1,2,3), size=100, replace=TRUE)
sum(s == 1)
sum(s == 2)
sum(s == 3)
s <- sample(c('A', 'B', 'C'), size=100, replace=TRUE)
sum(s == 'A')
sum(s == 'B')
sum(s == 'C')
doorsWithCarEachNight
doorsWithCarEachNight <- sample(c('A', 'B', 'C'), size=100, replace=TRUE)
personFirstChoiceEachNight <- sample(c('A', 'B', 'C'), size=100, replace=TRUE)
sum(personFirstChoiceEachNight == 'A')
sum(personFirstChoiceEachNight == 'B')
sum(personFirstChoiceEachNight == 'C')
df <- data.frame(CarDoor=doorsWithCarEachNight, PersonChoice=personFirstChoiceEachNight)
df
head(df)
doorsWithCarEachNight == personFirstChoiceEachNight
agreements <- doorsWithCarEachNight == personFirstChoiceEachNight
probWinIfNoSwitch <- sum(agreements)
probWinIfNoSwitch <- sum(agreements) / length(agreements)
probWinIfSwitch <- (length(agreements) - sum(agreements)) / length(agreements)
probWinIfSwitch
probWinIfNoSwitch
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/Module 1 - Introduction/MontyHallProblem.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/Module 1 - Introduction/MontyHallProblem.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/Module 1 - Introduction/MontyHallProblem.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/Module 1 - Introduction/MontyHallProblem.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/Module 1 - Introduction/MontyHallProblem.R', echo=TRUE)
popn.size =  1000000  # population of size 1 million
clear #
popn.size =  1000000  # population of size 1 million
pd  = .001 			  # probability of an individual having the disease
pdt = .95             #probability of an individual having the disease testing positive
pct = .10             # probability of an individual not having the disease testing positive.
?sample
popn = sample(c("D","C"), size=popn.size, replace=TRUE, prob=c(pd,1-pd))
popn #
popn[1:60]                ## check the first 60 "people"
sum(popn == "D")   ## count how many people with the disease
test = function(x) {
if (x == "D")
sample(c("P","N"), size=1, prob=c(pdt,1 - pdt))
else
sample(c("P","N"), size=1, prob=c(pct,1 - pct))
}
popn.test = mapply(test, popn,USE.NAMES=FALSE)
popn.test[1:40]
popn.pos = popn[popn.test == "P"]   ##  the number testing positive
print(sum(popn.pos == "D")/length(popn.pos))
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/PRACTICALS/Practical1_FalsePositive.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/PRACTICALS/Practical1_FalsePositive.R', echo=TRUE)
car.door <- sample(c('A', 'B', 'C'), size=100, replace=TRUE)
first.choice <- sample(c('A', 'B', 'C'), size=100, replace=TRUE)
confusion.table <- table(car.door, first.choice)
confusion.table
agree <- sum(diag(confusion.table))
agree
probWinIfSwitch <- agree / sum(confusion.table); probWinIfSwitch
probWinIfNoSwitch <- 1 - probWinIfSwitch; probWinIfNoSwitch
sim.results <- numeric(0) # null vector to collect results
for (i in 1:1000) {
# number of 1's in sample of 21 (0,1)'s
num.condition1 <- sum(sample(0:1, size=21, replace=TRUE))
sim.results <- c(sim.results, num.condition1) # accumulate incidences of 1's
}
table(sim.results) # frequency of counts out of 21
sim.results
table(sim.results) # frequency of counts out of 21
sum(sim.results == 3)
sum(sim.results == 10)
m = 1:100
sum(m % 2 == 0)
6 % 2
7 %% 3
6 %% 3
sum(m %% 2 == 0)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/")
source('/datascience/projects/statisticallyfit/github/R/RStatistics/FORMULAS.R', echo=FALSE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/INTERPRET.R', echo=FALSE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/PLOTTING.R', echo=FALSE)
load("data/Exercises and Examples/REPELLENT.Rdata")
load("data/Exercises and Examples/EXECSAL.Rdata")
View(EXECSAL)
View(REPELLENT)
REPELLENT$TYPE == "Lotion/Cream"
types <- c()
for(i in 1:nrow(REPELLENT)){
if(REPELLENT$TYPE[i] == "Lotion/Cream"){
types = c(types, 1)
} else {
types = c(types, 0)
}
}
types
as.factor(REPELLENT$TYPE)
ifelse(REPELLENT$TYPE == "Lotion/Cream", 1, 0)
REPELLENT$TYPE[1]
df <- data.frame(REPELLENT$TYPE, stringsAsFactors = FALSE)
df
df <- c(data.frame(REPELLENT$TYPE, stringsAsFactors = FALSE))
df
types = REPELLENT$TYPE
contrasts(factor(types))
cs = contrasts(factor(types))
cs
class(cs)
factor(types)
repellentData <- data.frame(COSTPERUSE=REPELLENT$COST, MAXHOURS=REPELLENT$HOURS,TYPE=REPELLENT$TYPE)
head(repellentData)
repellentData$TYPE[repellentData$TYPE == "Lotion/Cream"] <- 1
repellentData$TYPE[repellentData$TYPE == "Lotion/Cream"] <- "1"
repellentData$TYPE[repellentData$TYPE == "Lotion/Cream"] <- as.factor("1")
factor(REPELLENT$TYPE, laebls=c(0,1))
factor(REPELLENT$TYPE, laebls=c("0","1"))
levels(REPELLENT$TYPE) <- c('0', '1')
REPELLENT$TYPE
REPELLENT
load("data/Exercises and Examples/REPELLENT.Rdata")
levels(repellentData) <- c('0', '1')
repellentData
levels(repellentData$TYPE) <- c('0', '1')
repellentData
repellent.dummy.lm <- lm(COSTPERUSE ~ TYPE, data=repellentData)
summary(repellent.dummy.lm)
g <- ggplot(repellentData, aes(x = TYPE, y = COSTPERUSE))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Type", y="Cost per use ($)") +
stat_smooth(method="lm", col="red", lwd=1)
g <- ggplot(repellentData, aes(x = TYPE, y = COSTPERUSE))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Type", y="Cost per use ($)") +
stat_smooth(method="lm", col="red", lwd=1)
library(ggplot2)
g <- ggplot(repellentData, aes(x = TYPE, y = COSTPERUSE))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Type", y="Cost per use ($)") +
stat_smooth(method="lm", col="red", lwd=1)
g <- ggplot(repellentData, aes(x = TYPE, y = COSTPERUSE))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Type", y="Cost per use ($)")
g <- ggplot(REPELLENT, aes(x = TYPE, y = COST))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Type", y="Cost per use ($)")
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Mosquito Repellent Type", y="Cost per use ($)")
repellent.dummy.lm2 <- lm(COSTPERUSE ~ TYPE, data=REPELLENT)
repellent.dummy.lm2 <- lm(COST ~ TYPE, data=REPELLENT)
summary(repellent.dummy.lm2)
lm(COST ~ TYPE, data=REPELLENT)
repellent.dummy.lm2 <- lm(HOURS ~ TYPE, data=REPELLENT)
summary(repellent.dummy.lm2)
g <- ggplot(REPELLENT, aes(x = TYPE, y = HOURS))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Mosquito Repellent Type", y="Maximum Protection (hours))")
g <- ggplot(REPELLENT, aes(x = TYPE, y = COST))
g + geom_point(shape=19, color="dodgerblue", size=3) +
labs(x="Mosquito Repellent Type", y="Cost per use ($)")
summary(repellent.dummy.lm2)
summary(repellent.dummy.lm)
load("data/Exercises and Examples/GASTURBINE.Rdata")
nrow(GASTURBINE)
options(digits=3)
X <- c(1,1,3,3)
Y <- c(1,3,4,6)
xy.lm <- lm(Y ~ X, x=TRUE)
summary(xy.lm)
xy.lm$coefficients
cbind(y, xy.lm$fitted.values, xy.lm$residuals)
cbind(Y, xy.lm$fitted.values, xy.lm$residuals)
xy.lm$x
print(xy.lm$x)
cbind(Y, xy.lm$fitted.values, xy.lm$residuals)
theYHats <- X %*% xy.lm$coef
xy.lm$coefficients
theYHats <- X %*% xy.lm$coefficients
theYHats <- X %*% (xy.lm$coefficients)
theYHats <- X * (xy.lm$coefficients)
theYHats
theYHats <- X %*% c(0.5, 1.5)
X
theYHats <- xy.lm$x %*% xy.lm$coef
theYHats
theYHats <- xy.lm$x %*% xy.lm$coef; theYHats
xy.lm$fitted.values
cbind(Y, xy.lm$fitted.values, xy.lm$residuals)
class(xy.lm$fitted.values)
X <- c("A", "A", "B", "B")
g <- factor(X)
g <- factor(X); g
xy.lm <- lm(Y ~ g, x=TRUE)
summary(xy.lm)
cbind(Y, xy.lm$fitted.values, xy.lm$residuals)
theYHats <- xy.lm$x %*% xy.lm$coef
theYHats
summary(xy.lm)
Y #
theYHats + xy.lm$residuals
X <- c(1,1,3,3)
Y <- c(1,3,4,6)
# Fit the linear model, and include the argument x = T to store
# the design matrix
xy.lm <- lm(Y ~ X, x=TRUE)
summary(xy.lm)
# Vector of fitted coefs B-hat, vector of fitted vals Y-hat, and
# the design matrix X and residuals vector e-hat.
xy.lm$coefficients
cbind(Y, xy.lm$fitted.values, xy.lm$residuals)
# Print the design matrix
xy.lm$x
# FItted values are obtained this way: Y-hat = X * B-hat
theYHats <- xy.lm$x %*% xy.lm$coef; theYHats
# these are equal to the fitted values
xy.lm$fitted.values
plot(X, xy.lm$fitted.values)
abline(xy.lm)
plot(X, Y)
abline(xy.lm)
X <- c("A", "A", "B", "B")
g <- factor(X); g
Y <- c(1,3,4,6)
# fit the model and store design matrix
xy.lm <- lm(Y ~ g, x=TRUE)
summary(xy.lm)
cbind(Y, xy.lm$fitted.values, xy.lm$residuals)
# fitted model is Y-hat = X * B-hat
theYHats <- xy.lm$x %*% xy.lm$coef
theYHats
# Since they chose base level to be A (since they have gB), the intercepts
# are interpreted as: B0 = mean_A, B1 = mean_B - mean_A
# ((default base level is chosen alphanumerically, lesser letters
# go first as the base))
# Check Y = Y-hat + e-hat
Y #
theYHats + xy.lm$residuals
plot(X, Y)
Y #
plot(xy.lm$x, Y)
plot(xy.lm$x, xy.lm$fitted.values)
xy.lm$x
xy.lm$coefficients
X
xy.lm$x
class(xy.lm$x)
xy.lm$x[,1]
xy.lm$x[,2]
c(xy.lm$x[,2])
matrix(xy.lm$x[,2])
Y
plot(matrix(xy.lm$x[,2]), Y)
plot(xy.lm$x, xy.lm$fitted.values)
xsAs01s <- matrix(xy.lm$x[,2])
plot(xsAs01s, Y)
abline(xy.lm)
xy1.lm <- lm(Y ~ g - 1, x=TRUE)
summary(xy1.lm)
xy.lm
xy1.lm
summary(xy.lm)
xy1.lm$coefficients
cbind(Y, xy1.lm$fitted.values, xy1.lm$residuals)
xy.lm$x
xy1.lm$x
cbind(xy.lm$x, xy1.lm$x)
cbind(xy.lm$x, rep(4, "-"), xy1.lm$x)
cbind(xy.lm$x, replicate(4, "-"), xy1.lm$x)
cbind(xy.lm$x, replicate(4, "---"), xy1.lm$x)
cbind(xy.lm$x, replicate(4, "dash"), xy1.lm$x)
A <- matrix(c(1,2,3,4), nrow=2, byrow=TRUE)
B <- matrix(c(5,6))
B
B <- matrix(c(5,6), nrow=1)
B #
A %*% B #
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 3 - Simple Linear Regression/")
options(digits=3, show.signif.stars = FALSE)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 3 - Simple Linear Regression/")
options(digits=3, show.signif.stars = FALSE)
source("../Rfunctions.r")
dat1 <- read.table("worksheet1_data.txt", header=TRUE)
head(dat1)
attach(dat1)
xy.lm <- lm(ODP ~ SRP, data=dat1)
plot(ODP ~ SRP, data=dat1, ylab="oxygen demand percent", xlab="solids reduction percent")
abline(xy.lm)
summary(xy.lm)
anova(xy.lm)
betaCI(xy.lm)
cor(ODP, SRP)
cor(ODP, SRP) # strong, positive linear relation
cor(ODP, SRP)^2
3.23^2 # residual standard error on 31 degrees freedom
anova(xy.lm)
anv = anova(xy.lm)
anv$`Sum Sq`[1]
anv$`Sum Sq`[1] / (nrow(dat1) - 2)
3.23^2 # residual standard error on 31 degrees freedom
anv$`Sum Sq`[2] / (nrow(dat1) - 2)
betaCI(xy.lm)
par(mfrow=c(1,2))
plot(xy.lm, which=1:2, add.smooth=F)
library(ggplot2)
autoplot(xy.lm)
library(ggfortify)
autoplot(xy.lm)
plot(xy.lm, which=1:2, add.smooth=F)
autoplot(xy.lm)
shapiro.test(xy.lm$residuals)
s = shapiro.test(xy.lm$residuals) # no evidence to reject null of normality.
s$method
s$data.name
pred.df <- data.frame(SRP=c(10,20,30,40,50,60,70,80))
CI <- predict(xy.lm, interval="confidence", newdata=pred.df)
PI <- predict(xy.lm, interval="predict", newdata=pred.df)
CI
cbind(SRP, CI, PI)
cbind(pred.df$SRP, CI, PI)
par(mfrow=c(1,1))
plot(pred.df$SRP, CI[,1], type="b", pch=16, xlab="SRP", ylab="mean ODP",
main="Scatterplot of ODP ~ SRP, with predicted values and 95% confidence and prediction abnds")
main="Scatterplot of ODP ~ SRP, with predicted values and 95% confidence and prediction Bands")
plot(pred.df$SRP, CI[,1], type="b", pch=16, xlab="SRP", ylab="mean ODP",
main="Scatterplot of ODP ~ SRP, with predicted values and 95%
confidence and prediction abnds")
points(dat1$ODP, dat1$SRP)
legend(10, 50, lty=c(1, 2, 3))
legend(10, 50, lty=c(1, 2, 3), legend=c("observed values", "predicted values"))
lines(pred.df$SRP, CI[,2], lty=2) # lty = linetype, lty = 2 is dashed
CI
lines(pred.df$SRP, CI[,3], lty=2)
lines(pred.df$SRP, PI[,3], lty=3)
lines(pred.df$SRP, PI[,3], lty=3)
lines(pred.df$SRP, PI[,2], lty=3)
legend(10, 50, lty=c(1, 2, 3), legend=c("Line of best fit",
"95% Confidence Bands",
"95% Prediction Bands"))
legend(10, 42, pch=c(1,16), legend=c("observed values", "predicted values"))
betaCI(xy.lm)
