EX <- integrate(f.ex, 0, 1)
EX
names(EX)
EX$value
# c)
f.var <- function(x) { (x - EX$value)^2 * 2 * (1 - x)}
VAR.X <- integrate(f.var, 0, 1)
VAR.X$value
# NUMBER 3 Dice
# a)
diceSample <- sample(1:6, size=120, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
table(diceSample)/120
# b)
mean(diceSample) # true = 3.5
sqrt(var(diceSample)) # true = 1.708
# c)
barplot(table(diceSample))
hist(diceSample)
library(ggplot2)
df <- data.frame(diceSample)
ggplot(df, aes(diceSample)) + geom_histogram(binwidth=1, fill='dodgerblue')
rbind(w, pmf.W(w))
pmf.W(w)
sum(pmf.W(w))
mu.W <- pmf.W(1) * 1 + pmf.W(2) * 2 + pmf.W(3) * 3
mu.W
w*pmf.W(w)
sum(w*pmf.W(w))
sum(w^2 * pmf.W(w)) - mu.W^2
var.w <- mu2.W - mu.W^2
var.w
var.W <- sum(w^2 * pmf.W(w)) - mu.W^2
var.W
var.W <- sum(w^2 * pmf.W(w)) - mu.W^2
var.W
var.another.W <- pmf.W(1)*(1-mu.W)^2 + pmf.W(2)*(2-mu.W)^2 + pmf.W(3)*(3-mu.W)^2
var.another.W
f.X <- function(x) { 2*(1 - x) }
# a)
integrate(f.X, 0, 1) # so is valid prob func
f.ex <- function(x) {2*x*(1-x)}
EX <- integrate(f.ex, 0, 1)
EX
names(EX)
EX$value
# c)
f.var <- function(x) { (x - EX$value)^2 * 2 * (1 - x)}
VAR.X <- integrate(f.var, 0, 1)
VAR.X$value
diceSample <- sample(1:6, size=120, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
table(diceSample)/120
# b)
mean(diceSample) # true = 3.5
sqrt(var(diceSample)) # true = 1.708
sd(diceSample)
barplot(table(diceSample))
dice1 <- sample(1:6, size=10^4, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
dice2 <- sample(1:6, size=10^4, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
dice3 <- sample(1:6, size=10^4, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
dice1
diceSum <- dice1 + dice2 + dice3
diceSum
N <- 10^4
probLessTen <- sum(diceSum < 10) / N; probLessTen
head(dice1, dice2, dice3)
head(cbind(dice1, dice2, dice3))
df <- cbind(dice1, dice2, dice3)
df[6,]
unique(df[6,])
df[6,1] == df[6,2] == df[6,3]
df[6,1] == df[6,2] || df[6,1] == df[6,3] || df[6,2] == df[6,3]
rolls <- cbind(dice1, dice2, dice3)
c = -
c = 0
c = 0
c += 1
probFaceValuesAllDifferent
probFaceValuesAllDifferent <- count / N;
probFaceValuesAllDifferent
probFaceValuesAllDifferent <- count / N;
rolls <- cbind(dice1, dice2, dice3)
#unique(df[6,])
count <- 0
for (i in 1:N){
# if all of the rolls of the 3 dice are not the same for this iteration i,
if(rolls[i, 1] != rolls[i,2] && rolls[i,1] != rolls[i, 3] &&
rolls[i,2] != rolls[i,3]){
# then we do increment the count
count = count + 1
}
}
# the probability we are finding is:
probFaceValuesAllDifferent <- count / N;
probFaceValuesAllDifferent
count <- 0
unique(rolls)
head(unique(rolls))
head(rolls)
count <- 0
for (i in 1:N){
# if all of the rolls for this row i are unique,
if(unique(rolls[i, ]) == 3){
# then we increment the count
count = count + 1
}
}
count /
count / N
count <- 0
for (i in 1:N){
# if all of the rolls for this row i are unique,
if(unique(rolls[i, ]) == 3){
# then we increment the count
count = count + 1
}
}
count / N
count <- 0
for (i in 1:N){
# if all of the rolls of the 3 dice are not the same for this iteration i,
if(rolls[i, 1] != rolls[i,2] && rolls[i,1] != rolls[i, 3] &&
rolls[i,2] != rolls[i,3]){
# then we do increment the count
count = count + 1
}
}
count
count <- 0
for (i in 1:N){
# if all of the rolls for this row i are unique,
if(unique(rolls[i, ]) == 3){
# then we increment the count
count = count + 1
}
}
warnings()
count <- 0
for (i in 1:N){
# if all of the rolls for this row i are unique,
if(length(unique(rolls[i, ])) == 3){
# then we increment the count
count = count + 1
}
}
count
count.1 <- 0
for (i in 1:N){
# if all of the rolls of the 3 dice are not the same for this iteration i,
if(rolls[i, 1] != rolls[i,2] && rolls[i,1] != rolls[i, 3] &&
rolls[i,2] != rolls[i,3]){
# then we do increment the count
count.1 = count.1 + 1
}
}
# the probability we are finding is:
probFaceValuesAllDifferent.1 <- count.1 / N;
probFaceValuesAllDifferen.1
probFaceValuesAllDifferent.1
count.2 <- 0
for (i in 1:N){
# if all of the rolls for this row i are unique,
if(length(unique(rolls[i, ])) == 3){
# then we increment the count
count.2 = count.2 + 1
}
}
probFaceValuesAllDifferent.2 <- count.2 / N
assertthat::count.1 == count.2
assertthat(count.1 == count.2)
assert_that(count.1 == count.2)
count.1 == count.2
probFaceValuesAllDifferent.2
1 - pbinom(100, size=105, n = 0.10)
1 - pbinom(100, size=105, prob = 0.10)
pbinom(100, size = 105, prob = 0.10, lower.tail=FALSE)
1 - pbinom(100, size=105, prob = 0.90)
pbinom(100, size = 105, prob = 0.90, lower.tail=FALSE)
ppois(11, lambda=10, lower.tail = FALSE)
1 - ppois(11, lambda=10)
p = ppois(11, lambda=10, lower.tail = FALSE)
pbinom(2, size=8, prob=p, lower.tail = FALSE)
1 - pbinom(2, size=8, prob=p)
p = pgeom(2, prob=0.8, lower.tail = FALSE)
p = pgeom(2, prob=0.8, lower.tail = FALSE); p
p = pgeom(q=2, prob=0.8, lower.tail = FALSE); p
1 - pgeom(2, prob=0.8)
p = pgeom(q=3, prob=0.8, lower.tail = FALSE); p
p = pgeom(q=1, prob=0.8, lower.tail = FALSE); p
?pgeom
p = pgeom(q=2, prob=0.8, lower.tail = FALSE); p
p = pgeom(q=1, prob=0.8, lower.tail = FALSE); p
1 - pgeom(1, prob=0.8)
pbinom(3, size=10, prob = p, lower.tail=FALSE)
1 - pbinom(3, size=10, prob=p)
N <- 10^4
dice1 <- sample(1:6, size=N, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
dice2 <- sample(1:6, size=N, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
dice3 <- sample(1:6, size=N, replace=TRUE, prob=c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))
diceSum <- dice1 + dice2 + dice3
# part a) Probability that sum of face values < 10
probLessTen <- sum(diceSum < 10) / N; probLessTen
rolls <- cbind(dice1, dice2, dice3)
count.1 <- 0
for (i in 1:N){
# if all of the rolls of the 3 dice are not the same for this iteration i,
if(rolls[i, 1] != rolls[i,2] && rolls[i,1] != rolls[i, 3] &&
rolls[i,2] != rolls[i,3]){
# then we do increment the count
count.1 = count.1 + 1
}
}
# the probability we are finding is:
probFaceValuesAllDifferent.1 <- count.1 / N;
probFaceValuesAllDifferent.1
count.2 <- 0
for (i in 1:N){
# if all of the rolls for this row i are unique,
if(length(unique(rolls[i, ])) == 3){
# then we increment the count
count.2 = count.2 + 1
}
}
probFaceValuesAllDifferent.2 <- count.2 / N
probFaceValuesAllDifferent.2
# Test to make sure: Should be true, the two methods yield the same answer.
count.1 == count.2
1 - pbinom(100, size=105, prob = 0.90)
# method 2 of calculating
pbinom(100, size = 105, prob = 0.90, lower.tail=FALSE)
p = ppois(11, lambda=10, lower.tail = FALSE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/MATH260 Probability and Simulation/Assignment2_questions_1_4_5.R', echo=TRUE)
p = ppois(11, lambda=10, lower.tail = FALSE); p
1 - ppois(11, lambda=10)
pbinom(100, size = 105, prob = 0.90, lower.tail=FALSE)
p = ppois(11, lambda=10, lower.tail = FALSE); p
# method 2
1 - ppois(11, lambda=10)
pbinom(2, size=8, prob=p, lower.tail = FALSE)
# method 2
1 - pbinom(2, size=8, prob=p)
p = pgeom(q=1, prob=0.8, lower.tail = FALSE); p
# Method 2
1 - pgeom(1, prob=0.8)
pbinom(3, size=10, prob = p, lower.tail=FALSE)
# Method 2
1 - pbinom(3, size=10, prob=p)
p = pgeom(q=0, prob=0.8, lower.tail = FALSE); p
1 - pgeom(1, prob=0.8) # P(X >= 2) = P(X <= 1)
1 - pgeom(2, prob=0.8) # P(X >= 2) = P(X <= 1)
1 - pgeom(0, prob=0.8) # P(X >= 2) = P(X <= 1)
pbinom(3, size=10, prob = p, lower.tail=FALSE)
1 - pbinom(3, size=10, prob=p)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/Lecture_Chapter7_Transformations_Poppy.R', echo=TRUE)
ggplot(poppyData, aes(x=count, y=treat)) + stat_summary()
d=data.frame(drink=c("coffee","tea","water"), mean=c(3,6,2), lower=c(2.6,5.6,1.8), upper=c(3.5,6.3,2.8))
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower), width=0.2, size=1, color="blue") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=4, shape=21, fill="white")
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower),
width=0.2, size=2, color="gray") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=5, shape=19, fill="blue")
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower),
width=0.2, size=1, color="darkgray") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=5, shape=19, fill="blue")
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower),
width=0.2, size=1, color="black") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=5, shape=19, fill="blue")
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower),
width=0.1, size=1, color="black") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=5, shape=19, fill="blue")
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower),
width=0.1, size=1, color="purple") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=5, shape=19, fill="blue")
ggplot() +
geom_errorbar(data=d, mapping=aes(x=drink, ymin=upper, ymax=lower),
width=0.1, size=1, color="purple") +
geom_point(data=d, mapping=aes(x=drink, y=mean), size=5, shape=19, fill="white")
pred.df
ggplot() +
geom_errorbar(data=pred.df, mapping=aes(x=count, ymin=backT_lwr,
ymax=backT_upr),
with=0.1, size=1, color="purple") +
geom_point(data=pred.df, mapping=aes(x=count, y = backT_fit),
size=5, shape=19, fill="black")
pred.df
library(MASS)
boxcox(count ~ block + treat, data=poppyData, lambda=seq(from=0,to=1,by=0.01))
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/")
load("data/Exercises and Examples/DIESEL.Rdata")
load("data/Exercises and Examples/DIELSEL2.Rdata")
library(ggplot2)
options(digits=10, show.signif.stars = FALSE)
diesel.lm <- lm(PERFORM ~ BRAND + FUEL, data=DIESEL)
summary(diesel.lm)
attach(DIESEL)
interactionPlot(data=DIESEL, xFactor = "BRAND", traceFactor = "FUEL",
response="PERFORM")
interactionPlot(data=DIESEL, xFactor = "FUEL", traceFactor = "BRAND",
response="PERFORM")
interaction.plot(x.factor = BRAND, trace.factor = FUEL, response = PERFORM)
detach(DIESEL)
attach(DIELSEL2)
diesel.MISSING.XS.lm <-lm(PERFORM ~ X1 + X2 + X3 + X1X3 + X2X3, data=DIELSEL2)
diesel.MISSING.lm <- lm(PERFORM ~ FUEL + BRAND + FUEL:BRAND, data=DIELSEL2)
summary(diesel.MISSING.XS.lm)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
fuelData <- read.table("fuel.txt", header=TRUE)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
fuelData <- read.table("fuel.txt", header=TRUE)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/")
DIELSEL2
diesel.MISSING.lm <- lm(PERFORM ~ FUEL + BRAND + FUEL:BRAND, data=DIELSEL2)
summary(diesel.MISSING.lm) # see two parameters are missing, the interactions.
setwd('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/PRACTICALS/Practical_2_Perch/')
conc <- c(rep(seq(from = 0.5, to = 3, by = 0.5), 2))
conc #
# ys = skin response in rats
skin <- c(13.9, 14.08, 13.75, 13.32, 13.45, 13.59, 13.81, 13.99, 13.60, 13.39,
13.53, 13.64)
ratsData <- data.frame(Skin=skin, Conc=conc)
# Plotting data
plot(skin ~ conc) # seems negative x^3 model with B3 < 0
ggplot(ratsData, aes(x = Conc, y = Skin)) +
geom_point(shape=19, size=3, color="dodgerblue")
skin3.lm <- lm(Skin ~ Conc + I(Conc^2) + I(Conc^3), data=ratsData)
summary(skin3.lm)
betaCI(skin3.lm)
anova(skin3.lm)
skin4.lm <- lm(Skin ~ Conc + I(Conc^2) + I(Conc^3) + I(Conc^4), data=ratsData)
summary(skin4.lm)
betaCI(skin4.lm)
anova(skin4.lm)
skin6.lm <- lm(Skin ~ Conc + I(Conc^2) + I(Conc^3) + I(Conc^4)
+ I(Conc^5) + I(Conc^6), data=ratsData)
summary(skin6.lm)
anova(skin6.lm)
nrow(ratsData)
summary(diesel.lm)
anova(diesel.MISSING.lm)
nrow(DIELSEL2)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
cigarData <- read.table("FTCIGAR.txt", header=TRUE)
View(cigarData)
View(cigarData)
pairsQuantPlot(cigarData, 1:4)
cor.prob(cigarData)
cor.prob(cigarData)
cigar.lm <- lm(CO ~ TAR + NICOTINE + WEIGHT, data=cigarData)
cigar.lm <- lm(CO ~ TAR + NICOTINE + WEIGHT, data=cigarData)
summary(cigar.lm)
tarX.lm <- lm(TAR ~ NICOTINE + WEIGHT, data=cigarData)
R2.tar <- summary(tarX.lm)$r.squared
VIF.tar <- 1 / (1 - R2.tar)
VIF.tar
library(car)
vif(cigar.lm)
summary(cigarData[1:3])
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
options(digits=10, show.signif.stars = FALSE)
data("LifeCycleSavings")
View(LifeCycleSavings)
pairsQuantPlot(LifeCycleSavings, c(2:5, 1))
pairs(LifeCycleSavings, lower.panel = panel.smooth, upper.panel = panel.cor)
?pairs
pairs(LifeCycleSavings[, c(2:5,1)], lower.panel = panel.smooth,
upper.panel = panel.cor)
start.model <- lm(sr ~ 1, data=LifeCycleSavings)
full.model <- lm(sr ~ pop15 + pop75 + dpi + ddpi, data=LifeCycleSavings)
sr.lm <- step(start.model, direction = "forward", scope=list(lower=formula(start),
upper=formula(full.model)))
sr.lm <- step(start.model, direction = "forward", scope=formula(full.model))
step(full.model, direction = "backward", scope=formula(start.model))
sr.lm <- lm(sr ~ pop15 + ddpi, data=LifeCycleSavings)
summary(sr.lm)
autoplot(sr.lm)
shapiro.test(sr.lm$residuals)
plot(sr.lm, add.smooth = F, cook.levels = c(0.2, 0.5, 1.0))
par(mfrow=c(2,2))
plot(sr.lm, add.smooth = F, cook.levels = c(0.2, 0.5, 1.0))
?autoplot
k = 2; n = 50
h.mean = 2*(k + 1)/n; h.mean
plot(sr.lm, add.smooth = F, cook.levels = c(0.12, 0.5, 1.0))
plot(sr.lm, add.smooth = F, cook.levels = c(0.2, 0.5, 1.0))
cookd(sr.lm)
cooks.distance(sr.lm)
leveragePlot(sr.lm)
hatvalues(sr.lm)
?hatvalues
hs <- hatvalues(sr.lm)
class(hs)
c(hs)
data.frame(hs)
df <- data.frame(hs)
h.mean <- 2*(k + 1)/n #
h.mean
sum(hs > h.mean)
names(fit$model)
names(sr.lm$model)
hs > h.mean
influentialPoints <- function(fit){
hs <- hatvalues(fit)
k <- length(fit$model) - 1
n <- nrow(fit$model)
h.mean <- 2*(k+1)/n
isInfluential <- hs > h.mean
return(data.frame(InfluentialPoints=hs, CutOffInflMean=h.mean,
IsInfluential=isInfluential))
}
influentialPoints(sr.lm)
cooks.distance(sr.lm)
cks <- cooks.distance(sr.lm)
class(cks)
pf(cks, df1=3, df2=50-3)
qf(0.5, df1=3, df2=50-3, lower.tail=F)
pf(cks, df1=3, df2=50-3) > 50
any(pf(cks, df1=3, df2=50-3) > 50)
any(cks > 0.8)
qf(0.5, df1=3, df2=50-3, lower.tail=F)
qf(0.5, df1=3, df2=50-3, lower.tail=TRUE)
qf(0.5, df1=15, df2=50-15, lower.tail=TRUE)
qf(0.5, df1=15, df2=50-15, lower.tail=FALSE)
cooksDistance <- function(fit) {
cks <- cooks.distance(fit)
k <- length(fit$model) - 1
n <- nrow(fit$model)
Fcrit <- qf(0.5, df1=k+1, df2=n-k-1)
isInfluential <- cks > Fcrit
return(data.frame(CooksPoints=cks, CutOffFcrit=Fcrit,
IsInfluential=isInfluential))
}
cooksDistance(sr.lm)
which(cooks.distance(sr.lm) > 0.05)
cs <- cooksDistance(sr.lm)
cs$CooksPoints[Libya, ]
cs$CooksPoints["Libya", ]
cs$CooksPoints[nrow(cs)-1, ]
nrow(cs)
cs$CooksPoints[nrow(cs)-1]
preds <- predict(sr.lm)
preds#
sr <- LifeCycleSavings$sr #
pop15 <- LifeCycleSavings$pop15
ddpi <- LifeCycleSavings$ddpi
resids <- sr.lm$residuals
cbind(sr, preds, resids, pop15, ddpi)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 5 - Principles of Model Building/lecturedata/")
depressionData <- read.table("depression.txt", header=TRUE)
depress.A.lm <- lm(response ~ age * treat, data=depressionData, x=TRUE)
depress.A.lm$x
View(depressionData)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/ASSIGNMENTS/A2/")
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Rfunctions.R')
library(MASS)
options(digits=10, show.signif.stars = F)
insectData <- read.table("insect.txt", header=TRUE)
# choosing only the rows without the Count = 0
insectData.NoZero <- insectData[insectData$Count != 0, ]
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/ASSIGNMENTS/A2/")
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Rfunctions.R')
library(ggplot2)
options(digits=10, show.signif.stars = F)
bflowData <- read.table("bloodflow.txt", header=TRUE)
ggplot(bflowData, aes(x=AOT, y=BF)) +
geom_point(shape=19, size=3, color="dodgerblue") +
ggtitle("Scatterplot of Arterial Oxygen Tension (AOT) against Bloodflow (BF)")
bflowData <- read.table("bloodflow.txt", header=TRUE)
ggplot(bflowData, aes(x=AOT, y=BF)) +
geom_point(shape=19, size=3, color="navy") +
ggtitle("Scatterplot of Arterial Oxygen Tension (AOT) against Bloodflow (BF)")
ggplot(bflowData, aes(x=AOT, y=BF)) +
geom_point(shape=19, size=3) +
ggtitle("Scatterplot of Arterial Oxygen Tension (AOT) against Bloodflow (BF)")
bflow.1.lm <- lm(BF ~ AOT, data=bflowData)
anova(bflow.1.lm)
bflow.2.lm <- lm(BF ~ AOT + I(AOT^2), data=bflowData)
anova(bflow.2.lm) # quadratic model is significant, so continue
bflow.3.lm <- update(bflow.2.lm, .~. + I(AOT^3), data=bflowData)
anova(bflow.3.lm) # cubic isn't significant so just use quadratic.
df <- data.frame(BF=bflowData$BF, AOT=bflowData$AOT, AOT2=bflowData$AOT^2,AOT3=bflowData$AOT^3,AOT4=bflowData$AOT^4,AOT5=bflowData$AOT^5)
head(df)
formL = formula(~1)
formU = formula(~AOT + AOT2 + AOT3 + AOT4 + AOT5, data=df)
start.model <- lm(BF ~ 1, data=df)
step(start.model, direction = "forward", scope=list(lower=formL, upper=formU))
step(lm(BF ~ AOT + AOT2 + AOT3 + AOT4 + AOT5, data=df), direction = "backward", scope=list(lower=formL, upper=formU))
min.model <- lm(BF ~ 1, data=df)
max.model <- lm(BF ~ AOT + AOT2 + AOT3 + AOT4 + AOT5, data=df)
step.foward <- step(start.model, direction = "forward",
scope=list(lower=formL, upper=formU))
step.backward <- step(maxModel, direction = "backward",
scope=list(lower=formL, upper=formU))
step.backward <- step(max.model, direction = "backward",
scope=list(lower=formL, upper=formU))
anova(step.backward)
from = min(bflowData$AOT)
to = max(bflowData$AOT)
n <- nrow(bflowData)
preds <- data.frame(AOT=seq(from=from,to=to, len=n))
CI <- data.frame(predict(step.backward, interval="confidence", newdata=preds))
PI <- data.frame(predict(step.backward, interval="predict", newdata=preds))
aotXs = seq(from=from,to=to, len=n)
aot = seq(from=from,to=to, len=n)
head(df)
xs <- data.frame(AOT=aot, AOT2=aot^2, AOT3=aot^3, AOT4=aot^4)
CI <- data.frame(predict(step.backward, interval="confidence", newdata=preds))
PI <- data.frame(predict(step.backward, interval="predict", newdata=preds))
