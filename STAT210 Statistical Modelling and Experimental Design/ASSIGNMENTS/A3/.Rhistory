}
df[,1]
C(xVar, contr=c(df[,i]), how.many=1)
length(C(xVar, contr=c(df[,i]), how.many=1))
numRows = length(C(xVar, contr=c(df[,i]), how.many=1)) #testing
df.lm <- zeros(n=ncol(df), m=numRows)
for(i in 1:ncol(df)){
df.lm[,i] <- C(xVar, contr=c(df[,i]), how.many=1)
}
zeros(n=3, m=5)
df.lm <- zeros(m=ncol(df), n=numRows)
df.lm
for(i in 1:ncol(df)){
df.lm[,i] <- C(xVar, contr=c(df[,i]), how.many=1)
}
df.lm <- as.data.frame(df.lm)
df.lm
for(i in 1:ncol(df)){
df.lm[,i] <- C(xVar, contr=c(df[,i]), how.many=1)
}
df.lm
class(df.lm)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/FORMULAS.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 12 - ANOVA for Experimental Design/ContrastsReading.R', echo=TRUE)
makeOrthogonalContrasts.lm(xVar=melonData$Variety, mirror=TRUE)
xVar=melonData$Variety
numTreatments = length(unique(xVar))
df = data.frame(contr.helmert(n=numTreatments))
if(mirror) df <- as.data.frame(mirror(df))
df <- as.data.frame(mirror(df))
numRows = length(C(xVar, contr=c(df[,i]), how.many=1)) #testing
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
makeOrthogonalContrasts.lm(xVar=melonData$Variety, mirror=TRUE)
ACvBD
AvC
list(list(3), 4)
unlist(list(list(3), 4))
numTreatments = length(unique(xVar))
df = data.frame(contr.helmert(n=numTreatments))
df <- as.data.frame(mirror(df))
contrastHolder <- c()
for(i in 1:ncol(df)){
contrastHolder <- c(contrastHolder, C(xVar, contr=c(df[,i]), how.many=1))
}
contrastHolder
contrastHolder <- list()
for(i in 1:ncol(df)){
contrastHolder <- list(contrastHolder, C(xVar, contr=c(df[,i]), how.many=1))
}
contrastHolder
unlist(contrastHolder)
data.frame(contrastHolder)
matrix(contrastHolder)
flatten2 <- function(x) {
len <- sum(rapply(x, function(x) 1L))
y <- vector('list', len)
i <- 0L
rapply(x, function(x) { i <<- i+1L; y[[i]] <<- x })
y
}
flatten2(contrastHolder)
flatten2 <- function(x) {
len <- sum(rapply(x, function(x) 1L))
y <- vector('list', len)
i <- 0L
rapply(x, function(x) { i <<- i+1L; y[[i]] <<- x })
y
}
flatten.list <- function(x) {
len <- sum(rapply(x, function(x) 1L))
y <- vector('list', len)
i <- 0L
rapply(x, function(x) { i <<- i+1L; y[[i]] <<- x })
y
}
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
makeOrthogonalContrasts.lm(xVar=melonData$Variety, mirror=TRUE)
contrs = makeOrthogonalContrasts.lm(xVar=melonData$Variety, mirror=TRUE)
contrs = makeOrthogonalContrasts.lm(xVar=melonData$Variety, mirror=TRUE); contrs
contrs[1]
contrs[[1]]
melon.diffAllThree.lm <- lm(Yield ~ contrs[[1]] + contrs[[2]] + contrs[[3]], data=melonData, x=T)
melon.diffAllThree.lm
anova(melon.diffAllThree.lm)
names(contrs) = c("AvBCD","AvD","BvC")
contrs #
melon.diffAllThree.lm <- lm(Yield ~ contrs, data=melonData, x=T)
melon.diffAllThree.lm <- lm(Yield ~ contrs$AvBCD + contrs$AvD + contrs$BvC, data=melonData, x=T)
melon.diffAllThree.lm
data.frame(contrs)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
contrs = makeOrthogonalContrasts.lm(xVar=melonData$Variety, mirror=TRUE); contrs
contrs = makeOrthogonalContrasts.lm(xVar=melonData$Variety,
contrastNames=c("AvBCD","AvD","BvC"),
mirror=TRUE); contrs
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
contrs = makeOrthogonalContrasts.lm(xVar=melonData$Variety,
contrastNames=c("AvBCD","AvD","BvC"),
mirror=TRUE); contrs
cbind(melonData$Yield, contrs)
names(melonData)
names(melonData)[[2]]
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
mirrorHorizontal(melonData)
apply(melonData, 1, rev)
melonData <- data.frame(Yield=c(25.12, 17.25, 26.42, 16.08, 22.15, 15.92,
40.25, 35.25, 31.98, 36.52, 43.32, 37.10,
18.3, 22.6, 25.9, 15.05, 11.42, 23.68,
28.55, 28.05, 33.2, 31.68, 30.32, 27.58),
Variety=c(rep("A",6),rep("B",6),rep("C",6),rep("D",6)))
melonData
contrs = makeOrthogonalContrasts.lm(data=melonData,
contrastNames=c("AvBCD","AvD","BvC"),
mirror=TRUE); contrs
melon.diffAllThree.lm <- lm(Yield ~ AvBCD + AvD + BvC, data=contrs, x=T)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
contrs = makeOrthogonalContrasts.lm(data=melonData,
contrastNames=c("AvBCD","AvD","BvC"),
mirror=TRUE); contrs
melon.diffAllThree.lm <- lm(Yield ~ AvBCD + AvD + BvC, data=contrs, x=T)
melon.diffAllThree.lm
anova(melon.diffAllThree.lm)
helmerts = makeOrthogonalContrasts.df(factorNames=LETTERS[1:4],
contrastNames=c("AvBCD","BvCD","CvD"), mirror=TRUE)
helmerts
contrs = makeOrthogonalContrasts.lm(data=melonData,
contrastNames=c("AvBCD","BvCD","CvD"),
mirror=TRUE); contrs
melon.diffAllThree.lm <- lm(Yield ~ AvBCD + BvCD + CvD, data=contrs, x=T)
melon.diffAllThree.lm
anova(melon.diffAllThree.lm)
names(contrs)
ns = names(contrs)
paste(ns[1], " ~ ", paste(ns, sep=" + "))
paste(ns[1], " ~ ", paste(ns[-1], sep=" + "))
paste(ns[1], " ~ ", paste(ns[1:length(ns)], sep=" + "))
paste(ns[-1], sep=" + ")
c(rbind(ns))
paste(ns[-1], sep=" + ", collapse=" + ")
paste(ns[1], " ~ ", paste(ns[-1], sep=" + ", collapse=" + "))
makeFormulaFromData <- function(data){
ns = names(data)
return(formula(paste(ns[1], " ~ ", paste(ns[-1], sep=" + ", collapse=" + "))))
}
makeFormulaFromData(melonData)
data = melonData
ns = names(data)
formula(paste(ns[1], " ~ ", paste(ns[-1], sep=" + ", collapse=" + ")))
as.formula(paste(ns[1], " ~ ", paste(ns[-1], sep=" + ", collapse=" + ")))
makeFormulaFromData(contrs)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
makeFormulaFromData(contrs)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/DATA.R', echo=TRUE)
form = makeFormulaFromData(contrs)
form = makeFormulaFromData(contrs); form
melon.diffAllThree.lm
melon.diffAllThree.lm <- lm(form, data=contrs, x=T)
melon.diffAllThree.lm
anova(melon.diffAllThree.lm)
mat = matrix(c(2,0,-1,1,-1,1),nrow-3)
mat = matrix(c(2,0,-1,1,-1,1),nrow=3)
mat
mat = matrix(c(2,0,-1,1,-1,1),nrow=3, byrow=TRUE)
mat#
t(mat) %*% mat#
t(mat)
helmerts
t(helmerts) %*% helmerts
mat #
mat = matrix(c(2,-1,-1, 0,1,1),nrow=3)
mat
t(mat) %*% mat
mat = matrix(c(2,-1,-1, 0,1,-1),nrow=3)
t(mat) %*% mat
n <- 128
cond <- gl(4, n/4, labels=c("A", "B", "C","Control"))
dose <- gl(4, 4, length=n, labels=c("None", "Low", "Med", "High"), ordered=TRUE)
data <- data.frame(cond=cond, dose=dose)
data$y <- ifelse(data$cond=="Control", rnorm(n, mean=100, sd=10),
ifelse(data$cond=="A", rnorm(n, mean=110, sd=10),
rnorm(n, mean=120, sd=10)))
data$y <- ifelse(data$dose=="Low", data$y + 10,
ifelse(data$dose=="Med", data$y + 15,
data$y))
model1 <- lm(y ~ cond, data=data)
summary(model1)
levels(data$cond)
data$cond <- relevel(data$cond, ref="Control")
levels(data$cond)
model1.contrref <- lm(y ~ cond, data=data)
model2 <- lm(y ~ cond*dose, data=data)
model2
anova(model2)
data1 = data
contrasts(data1$cond) <- contr.sum
contrasts(data1$dose) <- contr.sum
model3 <- lm(y ~ cond*dose, data=data)
model3$contrasts
model3 <- lm(y ~ cond*dose, data=data1)
model3$contrasts
anova(model3)
anova(model2)
data2 <- data1
contrasts(data2$cond) <- contr.helmert
contrasts(data2$dose) <- contr.poly
data2$dose
model4 <- lm(y ~ cond*dose, data=data2)
model4$contrasts
anova(model4)
anova(melon.orthog.lm)
summary(melon.orthog.lm)
melonData1 = melonData
contrasts(melonData1$Variety) <- contr.helmert
melon.orthog2.lm <- lm(Yield ~ Variety, data=melonData1)
summary(melon.orthog2.lm)
melon.orthog.lm
anova(melon.orthog2.lm)
anova(melon.lm)
contrasts(melonData1$Variety) <- mirror(contr.helmert)
mirror(contr.helmert())
contrasts(melonData1$Variety) <- contr.helmert(4)
melon.orthog2.lm <- lm(Yield ~ Variety, data=melonData1)
melon.orthog2.lm
summary(melon.orthog2.lm)
contrasts(melonData1$Variety) <- mirror(contr.helmert(4))
melon.orthog3.lm <- lm(Yield ~ Variety, data=melonData1)
melon.orthog3.lm
melon.orthog.lm
mirror(contr.helmert(4))
melon.orthog.lm$contrasts
getContrastMatrix(melon.orthog.lm)
getContrastMatrix(melon.diffAllThree.lm)
melon.diffAllThree.lm
melon.orthog3.lm
summary(melon.diffAllThree.lm)
summary(melon.orthog3.lm)
anova(melon.orthog3.lm)
anova(melon.diffAllThree.lm)
melonData1 <- melonData
p = nlevels(melonData$Variety); p
contrasts(melonData1$Variety) <- mirror(contr.helmert(p))
melon.diffAllThree.lm2 <- lm(Yield ~ Variety, data=melonData1)
summary(melon.diffAllThree.lm2)
anova(melon.diffAllThree.lm)
anova(melon.diffAllThree.lm2) # just refer to summary table (equiv to F-table)
melon2.lm <- aov(Yield ~ Variety, data=melonData)
summary(melon2.lm, split=list(Variety=list(AvBCD=1, BvCD=1, CvD=1)))
melon2.lm <- aov(Yield ~ Variety, data=melonData1)
summary(melon2.lm, split=list(Variety=list(AvBCD=1, BvCD=1, CvD=1)))
melon2.lm <- aov(Yield ~ Variety, data=melonData)
summary(melon2.lm, split=list(Variety=list(AvBCD=1, BvCD=2, CvD=3)))
anova(melon.diffAllThree.lm)
getContrastMatrix(melon.diffAllThree.lm)
summary(melon2.lm, split=list(Variety=list(AvBCD=3, BvCD=2, CvD=1)))
anova(melon2.lm)
anova(melon.diffAllThree.lm)
melon2.lm <- aov(Yield ~ Variety, data=melonData1)
summary(melon2.lm, split=list(Variety=list(AvBCD=3, BvCD=2, CvD=1)))
summary(melon2.lm, split=list(Variety=list(AvBCD=1, BvCD=2, CvD=3)))
summary(aov(Yield ~ Variety, data=melonData1),
split=list(Variety=list(AvBCD=1, BvCD=2, CvD=3)))
anova(melon.diffAllThree.lm)
NLvMH <- c(-1/2, -1/2, 1/2, 1/2)
NvL <- c( 1,  -1,   0,    0 )
MvH <- c( 0,   0,   1,   -1 )
mat(c(NLvMH, NvL, MvH), ncol=3, byrow=TRUE)
mat = matrix(c(NLvMH, NvL, MvH), ncol=3, byrow=TRUE); mat#
mat = matrix(c(NLvMH, NvL, MvH), ncol=3, byrow=FALSE); mat#
t(mat) %*% mat #
getContrastMatrix(melon.diffAllThree.lm)
summary(melon.diffAllThree.lm)$coef[,1]
summary(melon.diffAllThree.lm)$coef
(37.41+19.49+29.9)/3
library(dplyr)
summarize(group_by(melonData, Variety), y.mean=mean(Yield))
summary(melon.diffAllThree.lm)$coef
26.820416667-2.110138889
(126.78 + 113.55)/2
3*20.49000000-(37.40333333+19.49166667+29.89666667)
20.49000000-(37.40333333+19.49166667+29.89666667)/3
getContrastMatrix(melon.diffAllThree.lm)
melonData
levels(melonData$Variety)
melonA = subset(melonData, Variety=="A")
melonA
melonB = subset(melonData, Variety=="B")
melonC = subset(melonData, Variety=="C")
melonD = subset(melonData, Variety=="d")
shapiro.test(melonA$Variety)
shapiro.test(melonA$Yield)
shapiro.test(melonB$Yield)
plot(melon.lm, which=2)
autoplot(melon.lm)
library(ggfortify)
autoplot(melon.lm)
leveneTest(melonData)
leveneTest(melonData$Yield)
leveneTest(melonData$Yield, group=melonData$Variety)
melonA = subset(melonData, Variety=="A")
melonB = subset(melonData, Variety=="B")
melonC = subset(melonData, Variety=="C")
melonD = subset(melonData, Variety=="D")
shapiro.test(melonA$Yield)
shapiro.test(melonB$Yield)
shapiro.test(melonC$Yield)
shapiro.test(melonD$Yield)
leveneTest(Yield, group=Variety, data=melonData)
?leveneTest
leveneTest(y=Yield, group=Variety, data=melonData)
melonData
?levene.test
leveneTest(y=Yield, group=Variety, data=melonData)
with(melonData, leveneTest(Yield, group=Variety, data=melonData))
with(melonData, leveneTest(Yield, group=Variety))
with(melonData, bartlett.test(Yield, group=Variet))
with(melonData, bartlett.test(Yield, g =Variety))
load('data/Exercises and Examples/GPA3.Rdata')
View(GPA3)
with(GPA3, leveneTest(y=GPA, group=CLASS))
ggplot(data=melonData, aes(x=Variety, y=Yield, colour=Variety)) +
geom_boxplot(size=2)
ggplot(data=melonData, aes(x=Variety, y=Yield, colour=Variety)) +
geom_boxplot(size=1)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 9 - Logistic Regression/")
leafData <- read.table("darlington.txt", header=TRUE)
leafData <- setNames(leafData, nm=c("LeafHeight", "Visited"))
leafDataFactor <- leafData
leafDataFactor$Visited <- factor(leafData$Visited)
head(leafData)
ggplot(leafDataFactor, aes(x=LeafHeight, colour=Visited)) +
geom_line(stat="density", size=2) +
xlab("Leaf height (cm)") + ylab("Density")
ggplot(data=melonData, aes(x=Yield, colour=Variety)) +
geom_line(stat="density", size=2)
ggplot(data=melonData, aes(x=Yield)) +
geom_line(stat="density", size=2)
ggplot(data=melonData, aes(x=Yield)) +
geom_histogram(size=2)
source('/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/PLOTTING.R', echo=TRUE)
normalityPlot(melon.diffAllThree.lm)
plot(melon.diffAllThree.lm, which=2)
normalityPlot(melon.diffAllThree.lm, size=3, colour="blue")
qqplot(x=melonA$Variety, y=melonA$Yield)
qplot(sample = Yield, data=melonA)
qplot(sample=Yield, data=melonData, color=Variety)
ggplot(data=melonD) + geom_qq(aes(sample=Yield)) + geom_abline(intercept=mean(melonD$Yield), slope=sd(melonD$Yield), color="red", size=1))
ggplot(data=melonD) + geom_qq(aes(sample=Yield)) + geom_abline(intercept=mean(melonD$Yield), slope=sd(melonD$Yield), color="red", size=1)
install.packages("qqplotr")
autoplot(melon.diffAllThree.lm, which=2)
?autoplot
qplot(sample = Yield, data=melonA)
qplot(sample=Yield, data=melonData, color=Variety, size=2)
n <- 10000
ggplot() + geom_qq(aes(sample = rnorm(n)))
with(melonData, leveneTest(Yield, group=Variety))
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/")
View(GPA3)
shapiro.test(GPA3$GPA)
ggplot(data=GPA3, aes(x=GPA, colour=CLASS)) +
geom_line(stat="density", size=2)
with(GPA3, leveneTest(GPA, group=CLASS))
with(GPA3, bartlett.test(GPA, g=CLASS))
ggQQ <- function(LM) # argument: a linear model
{
y <- quantile(LM$resid[!is.na(LM$resid)], c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
int <- y[1L] - slope * x[1L]
p <- ggplot(LM, aes(sample=.resid)) +
stat_qq(alpha = 0.5) +
geom_abline(slope = slope, intercept = int, color="blue")
return(p)
}
ggQQ(melon.diffAllThree.lm)
ggQQ <- function(LM) # argument: a linear model
{
y <- quantile(LM$resid[!is.na(LM$resid)], c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
int <- y[1L] - slope * x[1L]
p <- ggplot(LM, aes(sample=.resid)) +
geom_point(size=2)+
stat_qq(alpha = 0.5) +
geom_abline(slope = slope, intercept = int, color="blue")
return(p)
}
ggQQ <- function(LM) # argument: a linear model
{
y <- quantile(LM$resid[!is.na(LM$resid)], c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
int <- y[1L] - slope * x[1L]
p <- ggplot(LM, aes(sample=.resid)) +
geom_point(size=2)+
stat_qq(size=1) +
geom_abline(slope = slope, intercept = int, color="blue")
return(p)
}
ggQQ(melon.diffAllThree.lm)
qqPlot(melon.diffAllThree.lm)
ggplot(data=melonData, aes(sample=Yield)) + stat_qq() + geom_abline(intercept=mean(melonData$Yield), slope=sd(melonData$Yield))
options(digits=10, show.signif.stars = FALSE)
admitTable <- as.table(matrix(c(1198, 1493, 557, 1278), byrow=TRUE,nrow=2))
colnames(admitTable) <- c("Admitted", "Rejected")
rownames(admitTable) <- c("Male", "Female")
admitTable
# part 1 - analysis by odds ratio.
oddsRatio(mirror(admitTable))
oddsRatio(admitTable)
oddsMale.admit <- 1198/1493;oddsMale.admit
oddsFem.admit <- 557/1278; oddsFem.admit
oddsMale.admit/oddsFem.admit
# so the odds of being admitted for males is about 84% higher than for females.
oddsFem.admit/oddsMale.admit
# OR: the odds of being admitted for females is about 0.54 - 1 = 45.7% lower for
# females than for males.
# part 2 - analysis by proportions
cbind(admitTable, rowProbabilityHat(admitTable)[,1])
# props for males admitted is higher than for females
# but simpson's paradox here since proportions are opposite or nearly the
# same for when the departments are included (not collapsed)
admitData <- data.frame(gender=c(rep("Male",6),rep("Female",6)),
dept=rep(c("A","B","C","D","E", "F"),2),
admitted=c(512,353,120,138,53,22,89,17,202,131,94,24),
rejected=c(313,207,205,279,138,351,19,8,391,244,299,317))
admitData
admitData$total <- admitData$admitted + admitData$rejected
d <- data.frame(AdmitProp=admitData$admitted/admitData$total)
admitData.prop <- data.frame(Dept=LETTERS[1:6],
AdmitProp.Male=d$AdmitProp[1:6],
AdmitProp.Female=d$AdmitProp[7:12])
admitData.prop
# see now prop for males is lower. in depts A, B, F.
# NOW FOR REGRESSION -------------------------------------------------------------
count <- cbind(admitData$admitted, admitData$rejected)
admitData
admit.glm <- glm(count ~ gender + dept, data=admitData, family=binomial)
anova(admit.glm, test="Chisq")
anova(glm(count ~ dept + gender, data=admitData, family=binomial()))
summary(admit.glm)
setwd("/datascience/projects/statisticallyfit/github/R/RStatistics/STAT210 Statistical Modelling and Experimental Design/ASSIGNMENTS/A3")
discrData <- read.table("discrim.txt", header=TRUE)
hire.glm <- glm(HIRE ~ EXP + EDUC + GENDER,data=discrData, family=binomial)
hire.glm1 <- glm(HIRE ~ EXP + EDUC + GENDER,data=discrData, family=binomial)
hire.glm2 <- glm(HIRE ~ EDUC + GENDER + EXP,data=discrData, family=binomial)
hire.glm3 <- glm(HIRE ~ GENDER + EXP+EDUC,data=discrData, family=binomial)
combn(c("EXP", "EDUC", "GENDER"), m=3)
combn(x=c("EXP", "EDUC", "GENDER"), m=3)
perms(x=c("EXP", "EDUC", "GENDER"), m=3)
perms(x=c("EXP", "EDUC", "GENDER"))
perms(c("EXP", "EDUC", "GENDER"))
hire.glm4 <- glm(HIRE ~ EXP + GENDER + EDUC,data=discrData, family=binomial)
hire.glm5 <- glm(HIRE ~ EDUC + EXP +GENDER,data=discrData, family=binomial)
hire.glm3 <- glm(HIRE ~ GENDER + EDUC+EXP,data=discrData, family=binomial)
hire.glm3 <- glm(HIRE ~ GENDER + EXP + EDUC,data=discrData, family=binomial)
hire.glm6 <- glm(HIRE ~ GENDER + EDUC + EXP,data=discrData, family=binomial)
anova(hire.glm1)
anova(hire.glm1, test="Chisq")
hire.glm4
rbind(anova(hire.glm1, test="Chisq"), anova(hire.glm4, test="Chisq"))
rbind(anova(hire.glm2, test="Chisq"), anova(hire.glm5, test="Chisq"))
rbind(anova(hire.glm3, test="Chisq"), anova(hire.glm6, test="Chisq"))
summary(admit.glm)
65.438          -57.281
hire.glm
anova(hire.glm)
admit.glm
anova(admit.glm)
anova(glm(count ~ gender*dept, data=admitData, family=binomial))
anova(glm(count ~ gender*dept, data=admitData, family=binomial), test="Chisq")
nrow(admitData)
anova(hire.glm)
anova(admit.glm)
12-3
anova(glm(count ~ gender*dept, data=admitData, family=binomial), test="Chisq")
12-3-1
1-pchisq(20.20428, df=8)
admit.interact.glm <- glm(count ~ gender*dept, data=admitData, family=binomial)
ResidualDevianceTest(admit.interact.glm)
anova(admit.interact.glm)
anova(admit.interact.glm, test="Chisq")
ResidualDevianceTest(admit.interact.glm)
anova(admit.interact.glm, test="Chisq")
DevianceTest(admit.interact.glm)
anova(admit.interact.glm, test="Chisq")
summary(admit.interact.glm)
cof <- admit.interact.glm$coefficients[,1]
cof <- summary(admit.interact.glm)[,1]
cof <- coef(admit.interact.glm)[,1]
coef(admit.interact.glm)
summary(admit.interact.glm)
summary(admit.interact.glm)[,1]
summary(admit.interact.glm)$coef[,1]
cof <- summary(admit.interact.glm)$coef[,1]
exp(cof)-1
cof <- summary(admit.glm)$coef # all coefs are significant
cof
cof <- summary(admit.glm)$coef[,1] # all coefs are significant
cof
cof <- summary(admit.glm)$coef[,1:2] # all coefs are significant
cof
exp(cof[4,1]) / exp(cof[5,1])
exp(cof[4,1]) / exp(cof[5,1])-1
summary(admit.interact.glm)
admitData
with(admitData, interaction.plot(x.factor=dept, trace.factor=gender, response=admitted/total))
with(admitData, interaction.plot(x.factor=dept, trace.factor=gender, response=admitted/total))
admit.interact.glm <- glm(count ~ gender*dept, data=admitData, family=binomial)
anova(admit.interact.glm)
anova(admit.interact.glm, test="Chisq")
summary(admit.interact.glm)
