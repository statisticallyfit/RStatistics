source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
placekick <- read.csv("data/Placekick.csv")
head(placekick)
setwd("/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/learnstatistics/[ChristopherBilder] Analysis Of Categorical Data With R")
placekick <- read.csv("data/Placekick.csv")
head(placekick)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/learnstatistics/[PennState] GeneralizedLinearModels/BinaryLogisticRegression/Predictor_Discrete_One_ManyLevels_Smoke.R', echo=TRUE)
response <- cbind(c(400,416,188), c(1380,1823,1168)); response
d <- dim(response)
limit <- if(d[1] == 2) d[2] else d[1]
limit #
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
parentSmoke <- as.factor(c(2,1,0))
response <- cbind(c(400,416,188), c(1380,1823,1168)); response
# short way
BinaryLogisticRegression_T(response)
parentSmoke <- as.factor(c(2,1,0))
response <- cbind(c(400,416,188), c(1380,1823,1168)); response
# short way
BinaryLogisticRegression_T(response)
response <- cbind(yes = c(816, 188), no = c(3203, 1168)); response
# Logistic model (saturated)
BinaryLogisticRegression_T(response)
response <- cbind(c(400,416,188), c(1380,1823,1168)); response
# short way
BinaryLogisticRegression_T(response)
?residuals.glm
smoke.logistic <- glm(response ~ parentSmoke, family=binomial(link="logit"))
summary(smoke.logistic)$coef
residuals(smoke.logistic, type="deviance")
residuals(smoke.logistic, type="Pearson")
residuals(smoke.logistic, type="pearson")
responseTbl <- response #
response #
d <- dim(responseTbl)
# find how many levels in predictor X
limit <- if(d[1] == 2) d[2] else d[1]
pred <- as.factor(rev(0 : (limit - 1)))
fit <- glm(responseTbl ~ pred, family = binomial(link = "logit"))
s <- summary(fit)
s$call
s$terms
s$family
s$deviance
result <- list(Coefficients=s$coef, NullDeviance=s$null.deviance, ResidualDeviance=s$deviance,
NullDf=s$df.null, ResidDf=s$df.residual, DevianceResiduals=residuals(fit), PearsonResiduals=residuals(fit, type="pearson"))
result
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/learnstatistics/[PennState] GeneralizedLinearModels/BinaryLogisticRegression/Predictor_Discrete_One_ManyLevels_Smoke.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
parentSmoke <- as.factor(c(2,1,0))
response <- cbind(c(400,416,188), c(1380,1823,1168)); response
## Saturated model
# short way
BinaryLogisticRegression_T(response)
?predict.glm
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
result <- BinaryLogisticRegression_T(response)
result$PredictLogisticScale
result$PredictLinearScale
result$PredictLinearScale[1]
r <- result$PredictLinearScale
class(r)
data.frame(r)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
result$PredictLogisticScale
result$PredictLinearScale
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
result <- BinaryLogisticRegression_T(response)
result$PredictLogisticScale
result$PredictLinearScale
LikelihoodRatioTableTest(response)
ChiSquareIndependence(response)
sum(result$PearsonResiduals^2)
result$PearsonResiduals
result$PearsonResiduals^2
sum(result$PearsonResiduals^2)
smoke.logistic
smoke.logistic <- glm(response ~ parentSmoke, family=binomial(link="logit"))
smoke.logistic$y
## Saturated model
# short way
result <- BinaryLogisticRegression_T(response)
result$PredictLogisticScale
result$PredictLinearScale
# long way
smoke.logistic <- glm(response ~ parentSmoke, family=binomial(link="logit"))
summary(smoke.logistic)$coef
reduced.logistic <- glm(response ~ 1, family=binomial(link = "logit"))
summary(reduced.logistic)$coef
anova(reduced.logistic, smoke.logistic)
LikelihoodRatioTableTest(smoke)
LikelihoodRatioModelTest(reduced.logistic, smoke.logistic)
hosmerlem <-
function (y, yhat=n*prob, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,
1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
if (chisq<1*(10^(-20))) P="." else P=ifelse((g==2),1,pchisq(chisq, g - 2,lower.tail=FALSE))
yhat
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
response
response[,1]
result
yhat <- rowSums(response) * result$PredictLogisticScale
yhat
result$PredictLogisticScale
hosmerlem(response[,1], response[,1])
hosmerlem(response, result$PredictLogisticScale)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/learnstatistics/[PennState] GeneralizedLinearModels/BinaryLogisticRegression/ROCandHL.R', echo=TRUE)
yhat <- rowSums(response) * result$PredictLogisticScale; yhat
y <- response[,1]; y
hoslem.test(y, yhat)
hoslem.test(y, yhat, g=3)
model <- smoke.logistic
test <- hoslem.test(model$y, model$fitted)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
HosmerLemeshowTest_Calc(smoke.logistic, g=3)
hoslem.test(y, yhat, g=3)
y.hat <- rowSums(response) * result$PredictLogisticScale; yhat
y.hat <- rowSums(response) * result$PredictLogisticScale; y.hat
y <- response[,1]; y
cut_y.hat <- cut(y.hat,
breaks = quantile(y.hat, probs = seq(0, 1, 1/g)),
include.lowest = T)
g=3
cut_y.hat <- cut(y.hat,
breaks = quantile(y.hat, probs = seq(0, 1, 1/g)),
include.lowest = T)
cut_y.hat
quantile(y.hat, probs = seq(0, 1, 1/g))
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/learnstatistics/[PennState] GeneralizedLinearModels/BinaryLogisticRegression/ROCandHL.R', echo=TRUE)
breaks = quantile(y.hat, probs = seq(0, 1, 1/10))
quantile(y.hat, probs = seq(0, 1, 1/10))
cut_y.hat <- cut(y.hat,
breaks = quantile(y.hat, probs = seq(0, 1, 1/10)),
include.lowest = T)
cut_y.hat
cut_y.hat <- cut(y.hat,
breaks = quantile(y.hat, probs = seq(0, 1, 1/g)),
include.lowest = T)
cut_y.hat
class(cut_y.hat)
cbind(1 - y, y)
model #
model$y
1 - model$y
y.hat <- rowSums(response) * result$PredictLogisticScale
y.hat
y <-  model$y #
cut_y.hat
cbind(1 - y, y)
obs <- xtabs(cbind(1 - y, y) ~ cut_y.hat)
obs
cut_y.hat
cbind(1 - y.hat, y.hat)
expect <- xtabs(cbind(1 - y.hat, y.hat) ~ cut_y.hat)
expect
chisq <- sum((obs - expect)^2/expect)
chisq
if (chisq < 1*(10^(-20))) P="." else P=ifelse((g==2),1,pchisq(chisq, g - 2,lower.tail=FALSE))
yhat
y.hat
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
HosmerLemeshowTest_T(y, y.hat, g=3)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/learnstatistics/[PennState] GeneralizedLinearModels/BinaryLogisticRegression/Predictor_Discrete_One_ManyLevels_Smoke.R', echo=TRUE)
y <- response[,1]; y
HosmerLemeshowTest_T(y, y.hat, g=3)
smoke.logistic
HosmerLemeshowTest_Calc(smoke.logistic, g=3)
y.hat <- rowSums(response) * result$PredictLogisticScale; y.hat
y <- response[,1]; y
HosmerLemeshowTest_T(y, y.hat, g=3)
cut_y.hat <- cut(y.hat,
breaks = quantile(y.hat, probs = seq(0, 1, 1/g)),
include.lowest = T)
cut_y.hat
g=3
cut_y.hat <- cut(y.hat,
breaks = quantile(y.hat, probs = seq(0, 1, 1/g)),
include.lowest = T)
cut_y.hat
obs <- xtabs(cbind(1 - y, y) ~ cut_y.hat)
expect <- xtabs(cbind(1 - y.hat, y.hat) ~ cut_y.hat)
chisq <- sum((obs - expect)^2/expect)
chisq
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
HosmerLemeshowTest_T(y, y.hat, g=3)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
HosmerLemeshowTest_T(y, y.hat, g=3)
source('/datascience/projects/statisticallyfit/github/learningstatistics/RStatistics/StatsFormulas.R', echo=TRUE)
HosmerLemeshowTest_T(y, y.hat, g=3)
parentSmoke <- as.factor(c(2,1,0))
response <- cbind(c(400,416,188), c(1380,1823,1168)); response
## Saturated model
# short way
result <- BinaryLogisticRegression_T(response)
result$PredictLogisticScale
result$PredictLinearScale
# long way
smoke.logistic <- glm(response ~ parentSmoke, family=binomial(link="logit"))
summary(smoke.logistic)$coef
reduced.logistic <- glm(response ~ 1, family=binomial(link = "logit"))
summary(reduced.logistic)$coef
y.hat <- rowSums(response) * result$PredictLogisticScale; y.hat
y <- response[,1]; y
HosmerLemeshowTest_T(y, y.hat, g=3)
log(33/360)
temp.by.SES <- xtabs(count ~ delinquent + scout + SES, table); temp.by.SES
delinquent <- c("no","yes")
scout <- c("no", "yes")
SES <- c("low","med","high")
#table <- expand.grid(delinquent=c("yes","no"), scout=c("yes","no"),
table <- expand.grid(delinquent=delinquent, scout=scout, SES=SES)
#c(11,42,43,169, 14,20,104,132, 8,2,196,59)
table <- cbind(table, count=c(169,42,43,11,132,20,104,14,59,2,196,8))
table
temp.by.SES <- xtabs(count ~ delinquent + scout + SES, table); temp.by.SES
temp.by.scout <- xtabs(count ~ delinquent + SES + scout, table); temp.by.scout
temp.by.delinquent <- xtabs(count ~ scout + SES + delinquent, table); temp.by.delinquent
