Elite <- rep("No", nrow(collegeData))
Elite
Elite[collegeData$Top10perc > 50] = "Yes"
Elite
Elite <- as.factor(Elite)
eliteCollegeData <- data.frame(collegeData, Elite)
head(eliteCollegeData)
summary(eliteCollegeData)
ggplot(eliteCollegeData, aes(x = Elite, y=Outstate)) + geom_boxplot()
par(mfrow=c(2,2))
hist(collegeData$Top25perc, col=2, xlab="Top25perc", ylab="Count")
hist(collegeData$PhD, col=3, xlab="PhD", ylab="Count")
hist(collegeData$Grad.Rate, col=4, xlab="Grad Rate", ylab="Count")
hist(collegeData$Expend, col=5, xlab="% Expend", ylab="Count")
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/Lecture_Chapter7_Multicollinearity_FTCCIGAR.R', echo=TRUE)
getwd()
setwd("/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
setwd("/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT210 Statistical Modelling and Experimental Design/PLOTTING.R')
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R')
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R')
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R')
setwd("/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/lecturedata/")
setwd("/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT210 Statistical Modelling and Experimental Design/Chapter 6, 7 - Variable Screening, Transformations/")
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R')
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R')
source("/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/Rfunctions.R")
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R')
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R')
options(digits=10, show.signif.stars = FALSE)
cigarData <- read.table("FTCIGAR.txt", header=TRUE)
cigarData <- read.table("lecturedata/FTCIGAR.txt", header=TRUE)
pairsQuantPlot(cigarData, 1:4)
cor.prob(cigarData)
cor.prob(cigarData)
cigar.lm <- lm(CO ~ TAR + NICOTINE + WEIGHT, data=cigarData)
summary(cigar.lm)
tarX.lm <- lm(TAR ~ NICOTINE + WEIGHT, data=cigarData)
R2.tar <- summary(tarX.lm)$r.squared
VIF.tar <- 1 / (1 - R2.tar)
VIF.tar
library(car)
vif(cigar.lm) # tar and nicotine have high VIFs, but Weight not.
summary(cigarData[1:3])
setwd("/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/STAT330 Statistical Learning/Chapter 3 - Linear Regression")
library(ISLR)
library(car)
library(MASS)
fix(Boston)
head(Boston)
names(Boston)
boston.lm <- lm(medv ~ lstat, data=Boston)
summary(Boston)
summary(boston.lm)
options(show.signif.stars = FLASE)
options(show.signif.stars = FALSE)
confint(boston.lm)
meanCI(boston.lm, x.values=c(lstat))
fit <- boston.lm
meanCI(boston.lm, x.values="lstat")
meanCI(boston.lm, x.values=c("lstat"))
meanCI(boston.lm, x.values=c(5, 10, 15))
predict(boston.fit, newdata=data.frame(lstat=c(5,10,15)), interval="confidence")
predict(boston.lm, newdata=data.frame(lstat=c(5,10,15)), interval="confidence")
meanCI(boston.lm, x.values=(c(5, 10, 15)))
predict(boston.lm, newdata=data.frame(c(5,10,15)), interval="conf")
predictorNames <- names(fit$model)[-1]
predictorNames
x.values=c(5,10,15)
df <- data.frame(t(x.values))
df
rownames(df) <- ""
colnames(df) <- predictorNames
df
data.frame(lstat=c(5,10,15))
df <- data.frame(x.values)
df
rownames(df) <- ""
rownames(df) <- rep("", length(predictorNames))
colnames(df) <- predictorNames
source('/development/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R', echo=TRUE)
meanCI(boston.lm, x.values=x.values)
rep("", length(predictorNames))
rep(5, 2)
rep('', length(predictorNames))
source('/development/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R', echo=TRUE)
meanCI(boston.lm, x.values=x.values)
predict(boston.lm, newdata = data.frame(lstat=c(5, 10, 15)), interval="conf")
data.frame(rbind(x.values))
source('/development/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R', echo=TRUE)
predictCI(boston.lm, x.values = c(5,10,15))
predict(boston.lm, newdata = data.frame(lstat=c(5, 10, 15)), interval="pred")
df <- data.frame(cbind(x.values))
colnames(df) <- predictorNames
predict(fit, newdata = df, interval="prediction", level=level)
level=0.95
predict(fit, newdata = df, interval="prediction", level=level)
source('/development/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R', echo=TRUE)
predict(boston.lm, newdata = data.frame(lstat=c(5, 10, 15)), interval="conf")
modelPlot(boston.lm)
cookGraph(boston.lm)
plotConfidenceBands.lm(boston.lm)
plotConfPredBands.lm(boston.lm)
residualFitPlot(boston.lm)
normalityPlot(boston.lm)
partialPlot(boston.lm, "lstat")
r = residualFitPlot(boston.lm)
n = normalityPlot(boston.lm)
multiplot(r, n)
multiplot(r, n, cols=2)
multiplot(r, n, layout=matrix(1, 2), nrow=1, ncol=2)
multiplot(r, n, layout=matrix(c(1, 2), nrow=1, byrow=TRUE))
r #
multiplot(plotList=c(r, n), layout=matrix(c(1, 2), nrow=1, byrow=TRUE))
multiplot(plotList=c(r, n), cols=2, layout=matrix(c(1, 2), nrow=1, byrow=TRUE))
multiplot(plotList=c(r, n), cols=2)
multiplot(plotlist=c(r, n), cols=2)
multiplot(plotlist=c(r, n), cols=2, layout=matrix(c(1, 2), nrow=1, byrow=TRUE))
residualFitPlot(boston.lm)
normalityPlot(boston.lm)
cookGraph(boston.lm)
par(mfrow=c(2,2))
par(mfrow=c(1,2))
plot(boston.lm, which=c(1,2))
plot(boston.lm, which=c(3,5), cook.levels = c(0.2, 0.5, 1))
shapiro.test(supp.testDiffs.lm$residuals)
shapiro.test(boston.lm$residuals)
influence.leverageValues(boston.lm)
levInfo <- influence.leverageValues(boston.lm)
which(levInfo$IsInfluential)
outlierInfo <- influence.cooksDistances(boston.lm)
which(outlierInfo$IsInfluential)
cookInfo <- influence.cooksDistances(boston.lm)
slopeCI(boston.lm)
confint(boston.lm)
par(mfrow=c(2,2))
plot(boston.lm)
autoplot(boston.lm)
autoplot(boston.lm, which=c(1,2))
autoplot(boston.lm, which=c(1,2),size=3)
autoplot(boston.lm, which=c(3,4),size=2)
autoplot(boston.lm, which=c(5,6),size=2)
autoplot(boston.lm, which=c(7,8),size=2)
autoplot(boston.lm, color="hotpink", size=3)
?autoplot
autoplot(boston.lm, size=3)
autoplot(boston.lm)
autoplot(boston.lm, which=c(1,2))
residualFitPlot(boston.lm)
autoplot(boston.lm, which=c(3,4),size=2)
normalityPlot(boston.lm)
shapiro.test(boston.lm$residuals)
hatvalues(boston.lm)
autoplot(boston.lm, which=c(3,4),size=2)
autoplot(boston.lm, which=c(5,6),size=2)
plot(hatvalues(boston.lm))
par(mfrow=c(1,1))
plot(hatvalues(boston.lm))
autoplot(boston.lm, which=3)
autoplot(boston.lm, which=4)
autoplot(boston.lm, which=5)
autoplot(boston.lm, which=5, color="blue")
autoplot(boston.lm, which=5, colour="blue")
autoplot(boston.lm, which=5, colour="hotpink")
autoplot(boston.lm, which=5, colour="purple", size=3)
autoplot(boston.lm, which=5, colour="purple", size=2)
autoplot(boston.lm, which=5, colour="purple")
autoplot(boston.lm, which=5, colour="purple", size=3, shape=1)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=2)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=3)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=4)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=5)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=6)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=7)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=8)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=9)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=10)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=11)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=12)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=13)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=14)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=15)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=16)
autoplot(boston.lm, which=5, colour="purple", size=3)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=17)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=18)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19)
autoplot(boston.lm, which=5, colour="purple", size=3)
autoplot(boston.lm, which=5, colour="purple", size=4)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=19)
autoplot(boston.lm, which=5, colour="purple", size=2, shape=19)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=20)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=20)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=21)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=22)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=2)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=23)
autoplot(boston.lm, which=5, colour="purple", size=4, shape=24)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19, linetype=2)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19, linetype=1)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19, line.size=2)
autoplot(boston.lm, which=5, colour="purple", size=3, shape=19, linetype="solid")
df <- data.frame(StudentResid=rstudent(bostom.lm), Leverage=hatvalues(boston.lm))
df <- data.frame(StudentResid=rstudent(boston.lm), Leverage=hatvalues(boston.lm))
nrow(df)
ggplot(data=df, aes(x=Leverage, y = StudentResid)) + geom_point(size=3, shape=19, colour="lavendar") + geom_hline(yintercept=0, size=1, linetype="longdash", colour="red") + ggtitle("Residuals vs Leverage") + xlab("Leverage") + ylab("Studentized Residuals")
ggplot(data=df, aes(x=Leverage, y = StudentResid)) + geom_point(size=3, shape=19, colour="lavender") + geom_hline(yintercept=0, size=1, linetype="longdash", colour="red") + ggtitle("Residuals vs Leverage") + xlab("Leverage") + ylab("Studentized Residuals")
ggplot(data=df, aes(x=Leverage, y = StudentResid)) + geom_point(size=3, shape=19, colour="blue") + geom_hline(yintercept=0, size=1, linetype="longdash", colour="red") + ggtitle("Residuals vs Leverage") + xlab("Leverage") + ylab("Studentized Residuals")
ggplot(data=df, aes(x=Leverage, y = StudentResid)) + geom_point(size=3, shape=19, colour="blue") + geom_hline(yintercept=0, size=2, linetype="longdash", colour="red") + ggtitle("Residuals vs Leverage") + xlab("Leverage") + ylab("Studentized Residuals")
ggplot(data=df, aes(x=Leverage, y = StudentResid)) + geom_point(size=3, shape=19, colour="blue") + geom_hline(yintercept=0, size=2, linetype="dash", colour="red") + ggtitle("Residuals vs Leverage") + xlab("Leverage") + ylab("Studentized Residuals")
autoplot(boston.lm, which=c(1,2))
autoplot(boston.lm, which=c(3,4))
normalityPlot(boston.lm)
normalityPlot <- function(fit, size=3, colour="black"){
autoplot(fit, which=2, size=size, shape=19, colour=colour)
}
normalityPlot <- function(fit, size=3, colour="black"){
autoplot(fit, which=2, size=size, shape=19, colour=colour)
}
normalityPlot(boston.lm)
normalityPlot <- function(fit, size=2, colour="black"){
autoplot(fit, which=2, size=size, shape=19, colour=colour)
}
normalityPlot(boston.lm)
autoplot(boston.lm, which=2, size=size, shape=19, colour=colour, linetype="longdash", linecolour="red")
autoplot(boston.lm, which=2, size=size, shape=19, colour="black", linetype="longdash", linecolour="red")
autoplot(boston.lm, which=2, size=2, shape=19, colour="black", linetype="longdash", linecolour="red")
autoplot(boston.lm, which=2, size=2, shape=19, colour="black", linetype="longdash", line.colour="red")
autoplot(boston.lm, which=c(3,4),size=2)
cookGraph(boston.lm)
cookGraph(boston.lm)
autoplot(boston.lm, which=c(3,4),size=2)
autoplot(boston.lm, which=4,size=2)
cookGraph(boston.lm)
data(Cars93)
cars_lm <- lm(Price ~ Passengers + Length + RPM, data = Cars93)
gg_cooksd(cars_lm)
gg_cooksd <- function(fitted.lm, label = TRUE, show.threshold = TRUE, threshold = "convention", scale.factor = 0.5) {
handle_exception(fitted.lm, "gg_cooksd")
# obtain linear model matrix
lm_matrix <- fortify(fitted.lm)
lm_matrix[, "rowname"] <- 1:nrow(lm_matrix)
# threshold for outliar
cooksd = lm_matrix[, ".cooksd"]
n = nrow(lm_matrix)
# compute the threshold value for cook's distance plot
if (threshold == "matlab") {
threshold = mean(cooksd) * 3
}
else if (threshold == "baseR") {
threshold = c(0.5, 1)
}
else if (threshold == "convention") {
threshold = c(4/n, 1)
}
else {
stop("invalid threshold specified for gg_cooksd")
}
# window limit
limit = max(cooksd, na.rm = T)
margin_factor = 5
margin = round(limit / margin_factor)
max_cook = limit + margin
.cooksd <- NULL
base_plot <- (ggplot(fitted.lm, aes(1:nrow(lm_matrix), .cooksd, ymin = 0, ymax = cooksd)) +
geom_point(size = scale.factor) +
geom_linerange(size = scale.factor) +
xlab("Observation Number") +
ylab("Cook's distance") +
ggtitle("Cook's Distance Plot") +
ylim(0, max_cook))
# labelling of potential outliers
if (label) {
out_inds <- which(cooksd < min(threshold))
lm_matrix[out_inds, "rowname"] <- rep("", length(out_inds))
base_plot = base_plot + geom_text(label = lm_matrix[, "rowname"], nudge_x = 3, color = "indianred3")
}
# showing threshold for outliers
if (show.threshold) {
if (min(threshold) > max_cook) {
message("Cut-off for outliers too big to be shown in Cook's Distance plot.")
}
else {
for (i in 1:length(threshold)) {
if (threshold[i] > max_cook) {
next
}
base_plot = base_plot + geom_hline(yintercept = threshold[i], linetype = "dashed", color = "indianred3", size = scale.factor)
}
}
}
return(base_plot)
}
data(Cars93)
cars_lm <- lm(Price ~ Passengers + Length + RPM, data = Cars93)
gg_cooksd(cars_lm)
gg_cooksd <- function(fitted.lm, label = TRUE, show.threshold = TRUE, threshold = "convention", scale.factor = 0.5) {
# obtain linear model matrix
lm_matrix <- fortify(fitted.lm)
lm_matrix[, "rowname"] <- 1:nrow(lm_matrix)
# threshold for outliar
cooksd = lm_matrix[, ".cooksd"]
n = nrow(lm_matrix)
# compute the threshold value for cook's distance plot
if (threshold == "matlab") {
threshold = mean(cooksd) * 3
}
else if (threshold == "baseR") {
threshold = c(0.5, 1)
}
else if (threshold == "convention") {
threshold = c(4/n, 1)
}
else {
stop("invalid threshold specified for gg_cooksd")
}
# window limit
limit = max(cooksd, na.rm = T)
margin_factor = 5
margin = round(limit / margin_factor)
max_cook = limit + margin
.cooksd <- NULL
base_plot <- (ggplot(fitted.lm, aes(1:nrow(lm_matrix), .cooksd, ymin = 0, ymax = cooksd)) +
geom_point(size = scale.factor) +
geom_linerange(size = scale.factor) +
xlab("Observation Number") +
ylab("Cook's distance") +
ggtitle("Cook's Distance Plot") +
ylim(0, max_cook))
# labelling of potential outliers
if (label) {
out_inds <- which(cooksd < min(threshold))
lm_matrix[out_inds, "rowname"] <- rep("", length(out_inds))
base_plot = base_plot + geom_text(label = lm_matrix[, "rowname"], nudge_x = 3, color = "indianred3")
}
# showing threshold for outliers
if (show.threshold) {
if (min(threshold) > max_cook) {
message("Cut-off for outliers too big to be shown in Cook's Distance plot.")
}
else {
for (i in 1:length(threshold)) {
if (threshold[i] > max_cook) {
next
}
base_plot = base_plot + geom_hline(yintercept = threshold[i], linetype = "dashed", color = "indianred3", size = scale.factor)
}
}
}
return(base_plot)
}
data(Cars93)
cars_lm <- lm(Price ~ Passengers + Length + RPM, data = Cars93)
gg_cooksd(cars_lm)
fortify(boston.lm)
ff <- fortify(boston.lm)
class(ff)
names(ff)
lm_matrix <- fortify(boston.lm)
lm_matrix[, "rowname"] <- 1:nrow(lm_matrix)
head(lm_matrix)
install.packages("lindia")
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
data(Cars93)
cars_lm <- lm(Price ~ Passengers + Length + RPM, data = Cars93)
gg_cooksd(cars_lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
gg_cooksd(cars_lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
fit <- boston.lm
data <- fit$model
data$Obs <- 1:nrow(data)
data$Cooks <- cooks.distance(fit)
cook.cutOff <- influence.cooksDistances(fit)$Cut[1]
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
source('/datascience/projects/statisticallyfit/github/learningmathstat/RStatistics/PLOTTING.R', echo=TRUE)
cooksPlot(boston.lm)
autoplot(boston.lm, which=c(5,6),size=2)
which(levInfo$IsInfluential)
head(levInfo)
length(levInfo$IsInfluential)
sum(levInfo$IsInfluential)
which.max(levInfo$InfluentialPoints)
levInfo$InfluentialPoints[levInfo$IsInfluential]
head(levInfo)
levInfo$CutOffInflMean
which.max(cookInfo$CooksPoints)
boston2.lm <- lm(medv ~ lstat + age, data=Boston)
summary(boston2.lm)
vif(boston2.lm)
boston.all.lm <- lm(medv ~ ., data=Boston)
summary(boston.all.lm)
vif(boston.all.lm)
summary(boston.all.lm)$sigma # is the RSE (or s = standard error of regression line)
boston.notage.lm <- lm(medv ~ . -age, data=Boston)
summary(boston.notage.lm)
update(boston.all.lm, ~. -age)
boston.notage.update.lm <- update(boston.all.lm, ~. -age)
summary(boston.notage.update.lm)
summary(boston.notage.lm)
summary(lm(medv ~ lstat * age, data=Boston))
boston.square.lm <- lm(medv ~ lstat + I(lstat^2), data=Boston)
summary(boston.square.lm)
residualFitPlot(boston.square.lm)
shapiro.test(boston.square.lm$residuals)
normalityPlot(boston.square.lm)
anova(boston.lm, boston.square.lm)
NestedFTest(boston.lm, boston.square.lm)
autoplot(boston.square.lm)
boston.poly5.lm <- lm(medv ~ poly(lstat, 5))
boston.poly5.lm <- lm(medv ~ poly(lstat, 5), data=Boston)
summary(boston.poly5.lm)
NestedFTest(boston.lm, boston.poly5.lm)
NestedFTest(boston.square.lm, boston.poly5.lm)
NestedFTest(boston.lm, boston.poly5.lm)
anova(boston.lm, boston.poly5.lm)
autoplot(boston.poly5.lm)
boston.poly5.lm <- lm(medv ~ lstat + I(lstat^2) + I(lstat^3) + I(lstat^4)
+ I(lstat^5), data=Boston)
summary(boston.poly5.lm)
autoplot(boston.poly5.lm)
boston.poly6.lm <- lm(medv ~ poly(lstat, 6), data=Boston)
anova(boston.poly5.lm, boston.poly6.lm)
anova(boston.lm, boston.poly6.lm)
summary(boston.poly6.lm)
summary(lm(medv ~ log(rm), data=Boston))
data("Carseats")
head(Carseats)
is.factor(Carseats$Urban)
carseats.interact.lm <- lm(Sales ~ . + Income:Advertising + Price:Age, data=Carseats)
summary(carseats.interact.lm)
contrasts(Carseats$ShelveLoc)
data(Auto)
head(Auto)
auto.lm <- lm(mpg ~ horsepower, data=Auto)
summary(auto.lm)
anova(auto.lm)
summary(auto.lm)$sigma # s-squared
summary(auto.lm)$r.squared
summary(auto.lm)
meanCI(auto.lm, x.values=98)
predictCI(auto.lm, x.values = 98)
modelPlot(auto.lm)
plot(x = Auto$horsepower, y = Auto$mpg)
abline(auto.lm, col="red")
modelPlot(auto.lm)
residualFitPlot(auto.lm)
residualFitPlot(auto.lm)
autoplot(auto.lm, which=c(3,4))
autoplot(auto.lm, which=3) # scale-location plot makes funnel more evident
autoplot(auto.lm)
normalityPlot(auto.lm)
shapiro.test(auto.lm$residuals)
autoplot(auto.lm)
names(fortify(auto.lm))
auto.extra.lm <- fortify(auto.lm)
auto.extra.lm$.stdresid
s <- sqrt(summary(auto.lm)$sigma)
stdResid <- auto.lm$residuals / s
stdResid
data.frame(r1=stdResid, r2=auto.extra.lm$.stdresid)
auto.extra.lm$.sigma
outlier.test(auto.lm)
outlier.test(auto.lm$residuals)
outlierTest(auto.lm)
which.max(rstudent(auto.lm$residuals))
rst = rstudent(auto.lm$residuals)
rst = rstudent(auto.lm)
which.max(rstudent(auto.lm))
which.max(rstudent(auto.lm))
outlierTest(auto.lm)
fit = auto.lm
fit.forte <- fortify(fit)
fit.forte$.hat - hatvalues(auto.lm)
fit.forte$.stdresid - rstandard(auto.lm)
ls = c(1,2,3,4,5)
ls < -2 | ls > 2
outlier.outlierValues <- function(fit){
library(car)
srs = rstandard(fit)
isOutlier <- srs < -2 | srs > 2
print(outlierTest(fit)) # from car
return(data.frame(Fitted=fit$fitted.values, IsOutlier=isOutlier))
}
outlier.outlierValues(auto.lm)
source('/development/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R', echo=TRUE)
outlier.outlierValues(auto.lm)
df = outlier.outlierValues(auto.lm)
source('/development/projects/statisticallyfit/github/learningmathstat/RStatistics/FORMULAS.R', echo=TRUE)
df = outlier.outlierValues(auto.lm)
head(df)
which.max(df$StandardizedResiduals)
max(df$StandardizedResiduals)
df$StandardizedResiduals[df$StandardizedResiduals > 2 | df$StandardizedResiduals < -2]
